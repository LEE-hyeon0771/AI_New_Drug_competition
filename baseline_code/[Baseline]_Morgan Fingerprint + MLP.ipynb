{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pYzhJrEibIlq",
   "metadata": {
    "id": "pYzhJrEibIlq"
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f487ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 변동이 적은 특징을 제거하는데 사용하는 모듈\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 데이터 셋을 학습, 검증, 테스트 셋으로 분할하는 데 사용하는 모듈\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Pytorch에서 데이터셋 처리 및 배치 생성에 사용하는 모듈\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# rdkit : 화학 구조 및 데이터 처리를 위한 라이브러리\n",
    "# DataStructs : 데이터 구조 처리\n",
    "# PandasTools, AllChem : 화학 물질 처리\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import PandasTools, AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714740f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd5126",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd052629",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('open (1)/train.csv')\n",
    "test = pd.read_csv('open (1)/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7KbqRv6I19Rg",
   "metadata": {
    "id": "7KbqRv6I19Rg"
   },
   "outputs": [],
   "source": [
    "# SMILES 문자열을 사용하여 Molecule 열을 데이터프레임에 train, test 각각 추가\n",
    "PandasTools.AddMoleculeColumnToFrame(train,'SMILES','Molecule')\n",
    "PandasTools.AddMoleculeColumnToFrame(test,'SMILES','Molecule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "oXOFfJVW22DL",
   "metadata": {
    "id": "oXOFfJVW22DL"
   },
   "outputs": [],
   "source": [
    "# 주어진 mol을 Morgan fingerprint로 변환\n",
    "# Morgan fingerprint : 화학 물질의 구조와 성질을 나타내는 벡터 형식의 표현\n",
    "# GetHashedMorganFingerprint() : 화학물질 mol을 입력받아 해당 물질의 fingerprint로 반환\n",
    "\n",
    "def mol2fp(mol):\n",
    "    fp = AllChem.GetHashedMorganFingerprint(mol, 6, nBits=4096)\n",
    "    ar = np.zeros((1,), dtype=np.int8)\n",
    "    DataStructs.ConvertToNumpyArray(fp, ar)\n",
    "    return ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1MTlg0wx22DM",
   "metadata": {
    "id": "1MTlg0wx22DM"
   },
   "outputs": [],
   "source": [
    "# FPs column 추가 -> Morgan Fingerprint를 계산한 값\n",
    "\n",
    "train[\"FPs\"] = train.Molecule.apply(mol2fp)\n",
    "test[\"FPs\"] = test.Molecule.apply(mol2fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e34a2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 column만 추출\n",
    "\n",
    "train = train[['FPs','MLM', 'HLM']]\n",
    "test = test[['FPs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d289fc",
   "metadata": {},
   "source": [
    "## Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dade784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, target, transform, is_test=False):\n",
    "        self.df = df\n",
    "        self.target = target # HLM or MLM\n",
    "        self.is_test = is_test # train,valid / test\n",
    "\n",
    "        self.feature_select = transform   # transform = VarianceThreshold\n",
    "        if not self.is_test: \n",
    "            self.fp = self.feature_select.fit_transform(np.stack(df['FPs']))\n",
    "        else: # valid or test\n",
    "            self.fp = self.feature_select.transform(np.stack(df['FPs']))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fp = self.fp[index]\n",
    "        if not self.is_test: # test가 아닌 경우(label 존재)\n",
    "            label = self.df[self.target][index]\n",
    "            return torch.tensor(fp).float(), torch.tensor(label).float().unsqueeze(dim=-1) # feature, label\n",
    "\n",
    "        else: # test인 경우\n",
    "            return torch.tensor(fp).float() # feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c600a122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = VarianceThreshold(threshold=0.05)    # 변동이 0.05 이하인 특성을 제거\n",
    "\n",
    "train_MLM = CustomDataset(df=train, target='MLM', transform=transform, is_test=False)\n",
    "train_HLM = CustomDataset(df=train, target='HLM', transform=transform, is_test=False)\n",
    "\n",
    "# 모델에 입력될 특성의 수\n",
    "input_size = train_MLM.fp.shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cb36a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "CFG = {'BATCH_SIZE': 256,\n",
    "       'EPOCHS': 1000,\n",
    "       'INPUT_SIZE': input_size,\n",
    "       'HIDDEN_SIZE': 1024,\n",
    "       'OUTPUT_SIZE': 1,\n",
    "       'DROPOUT_RATE': 0.8,\n",
    "       'LEARNING_RATE': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "090fa2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,valid split\n",
    "train_MLM_dataset, valid_MLM_dataset = train_test_split(train_MLM, test_size=0.2, random_state=42)\n",
    "train_HLM_dataset, valid_HLM_dataset = train_test_split(train_HLM, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe86f36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MLM_loader = DataLoader(dataset=train_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_MLM_loader = DataLoader(dataset=valid_MLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)\n",
    "\n",
    "\n",
    "train_HLM_loader = DataLoader(dataset=train_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=True)\n",
    "\n",
    "valid_HLM_loader = DataLoader(dataset=valid_HLM_dataset,\n",
    "                              batch_size=CFG['BATCH_SIZE'],\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8CHzFfvrbnOM",
   "metadata": {
    "id": "8CHzFfvrbnOM"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "AWUlJIGf22DO",
   "metadata": {
    "id": "AWUlJIGf22DO"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # fc 레이어 3개와 출력 레이어\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
    "        \n",
    "        # 정규화\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.ln3 = nn.LayerNorm(hidden_size)        \n",
    "        \n",
    "        # 활성화 함수\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.ln3(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9IlcjfOB22DO",
   "metadata": {
    "id": "9IlcjfOB22DO"
   },
   "outputs": [],
   "source": [
    "model_MLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])\n",
    "model_HLM = Net(CFG['INPUT_SIZE'],CFG['HIDDEN_SIZE'],CFG['DROPOUT_RATE'],CFG['OUTPUT_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "IuQe4Za322DP",
   "metadata": {
    "id": "IuQe4Za322DP"
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer_MLM = torch.optim.Adam(model_MLM.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "optimizer_HLM = torch.optim.Adam(model_HLM.parameters(), lr=CFG['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e032e346",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "210fa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, model, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            valid_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in valid_loader:\n",
    "                    output = model(inputs)\n",
    "                    loss = criterion(output, targets)\n",
    "                    valid_loss += loss.item()\n",
    "                    \n",
    "            print(f'Epoch: {epoch}/{epochs}, Train Loss: {running_loss/len(train_loader)}, Valid Loss: {valid_loss/len(valid_HLM_loader)}')\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eda577c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start: MLM\n",
      "Epoch: 0/1000, Train Loss: 2092.469149502841, Valid Loss: 1900.7298177083333\n",
      "Epoch: 100/1000, Train Loss: 315.07490955699575, Valid Loss: 1596.1493326822917\n",
      "Epoch: 200/1000, Train Loss: 179.85753839666194, Valid Loss: 1462.0851643880208\n",
      "Epoch: 300/1000, Train Loss: 142.6571468006481, Valid Loss: 1484.1102294921875\n",
      "Epoch: 400/1000, Train Loss: 109.9487075805664, Valid Loss: 1524.2877197265625\n",
      "Epoch: 500/1000, Train Loss: 104.08066836270419, Valid Loss: 1559.7952473958333\n",
      "Epoch: 600/1000, Train Loss: 85.91273706609553, Valid Loss: 1561.7167561848958\n",
      "Epoch: 700/1000, Train Loss: 81.01566210660067, Valid Loss: 1538.984130859375\n",
      "Epoch: 800/1000, Train Loss: 75.30524097789417, Valid Loss: 1555.6198323567708\n",
      "Epoch: 900/1000, Train Loss: 66.95597908713601, Valid Loss: 1592.1287434895833\n",
      "Training Start: HLM\n",
      "Epoch: 0/1000, Train Loss: 3230.5881569602275, Valid Loss: 2635.5455729166665\n",
      "Epoch: 100/1000, Train Loss: 400.2231805974787, Valid Loss: 1366.9431559244792\n",
      "Epoch: 200/1000, Train Loss: 232.37529546564275, Valid Loss: 1468.9122721354167\n",
      "Epoch: 300/1000, Train Loss: 160.48013999245384, Valid Loss: 1505.7935791015625\n",
      "Epoch: 400/1000, Train Loss: 132.412221735174, Valid Loss: 1528.47900390625\n",
      "Epoch: 500/1000, Train Loss: 109.55325178666548, Valid Loss: 1434.99462890625\n",
      "Epoch: 600/1000, Train Loss: 109.11573999578303, Valid Loss: 1507.130126953125\n",
      "Epoch: 700/1000, Train Loss: 97.9840975674716, Valid Loss: 1503.8693440755208\n",
      "Epoch: 800/1000, Train Loss: 101.44558091597123, Valid Loss: 1543.0626627604167\n",
      "Epoch: 900/1000, Train Loss: 85.10477794300427, Valid Loss: 1500.6420491536458\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Start: MLM\")\n",
    "model_MLM = train(train_MLM_loader, valid_MLM_loader, model_MLM, criterion, optimizer_MLM, epochs=CFG['EPOCHS'])\n",
    "\n",
    "print(\"Training Start: HLM\")\n",
    "model_HLM = train(train_HLM_loader, valid_HLM_loader, model_HLM, criterion, optimizer_HLM, epochs=CFG['EPOCHS'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39bbce5",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cbc3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "test_HLM = CustomDataset(df=test, target=None, transform=transform, is_test=True)\n",
    "\n",
    "test_MLM_loader = DataLoader(dataset=test_MLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)\n",
    "\n",
    "test_HLM_loader = DataLoader(dataset=test_HLM,\n",
    "                             batch_size=CFG['BATCH_SIZE'],\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5d8a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(test_loader, model):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            output = model(inputs)\n",
    "            preds.extend(output.cpu().numpy().flatten().tolist())\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9794de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_MLM = inference(test_MLM_loader, model_MLM)\n",
    "predictions_HLM = inference(test_HLM_loader, model_HLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb42d64",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8e574c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  MLM  HLM\n",
       "0    TEST_000    0    0\n",
       "1    TEST_001    0    0\n",
       "2    TEST_002    0    0\n",
       "3    TEST_003    0    0\n",
       "4    TEST_004    0    0\n",
       "..        ...  ...  ...\n",
       "478  TEST_478    0    0\n",
       "479  TEST_479    0    0\n",
       "480  TEST_480    0    0\n",
       "481  TEST_481    0    0\n",
       "482  TEST_482    0    0\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('open (1)/sample_submission.csv')\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "569d8575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>MLM</th>\n",
       "      <th>HLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>5.561823</td>\n",
       "      <td>7.321818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>49.405273</td>\n",
       "      <td>84.464272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>26.698666</td>\n",
       "      <td>51.190384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>27.090666</td>\n",
       "      <td>56.688736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>26.869804</td>\n",
       "      <td>92.281189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>TEST_478</td>\n",
       "      <td>57.758179</td>\n",
       "      <td>87.065834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>TEST_479</td>\n",
       "      <td>76.982445</td>\n",
       "      <td>97.395988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>TEST_480</td>\n",
       "      <td>29.691576</td>\n",
       "      <td>67.671494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>TEST_481</td>\n",
       "      <td>38.914825</td>\n",
       "      <td>66.260643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>TEST_482</td>\n",
       "      <td>34.693527</td>\n",
       "      <td>89.391090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        MLM        HLM\n",
       "0    TEST_000   5.561823   7.321818\n",
       "1    TEST_001  49.405273  84.464272\n",
       "2    TEST_002  26.698666  51.190384\n",
       "3    TEST_003  27.090666  56.688736\n",
       "4    TEST_004  26.869804  92.281189\n",
       "..        ...        ...        ...\n",
       "478  TEST_478  57.758179  87.065834\n",
       "479  TEST_479  76.982445  97.395988\n",
       "480  TEST_480  29.691576  67.671494\n",
       "481  TEST_481  38.914825  66.260643\n",
       "482  TEST_482  34.693527  89.391090\n",
       "\n",
       "[483 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['MLM'] = predictions_MLM\n",
    "submission['HLM'] = predictions_HLM\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2eaf46fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('baseline_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d14e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "88a5da79f9030d36a713e3ceec9ed9a47a216907c035af9944c458137c4e5cb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
