{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5debec40",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for Chemical Bonds Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b50c4",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ad8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Impute NaN values\n",
    "median_value = train_data['AlogP'].median()\n",
    "train_data['AlogP'].fillna(median_value, inplace=True)\n",
    "test_data['AlogP'].fillna(median_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc544a",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6a27b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create polynomial features\n",
    "X = train_data.drop(columns=['id', 'SMILES', 'MLM', 'HLM'])\n",
    "X_test = test_data.drop(columns=['id', 'SMILES'])\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_test_poly = poly.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b3a2b",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d997d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 100, 'max_depth': 10},\n",
       " {'n_estimators': 100, 'max_depth': 10},\n",
       " {'n_estimators': 100, 'learning_rate': 0.1},\n",
       " {'n_estimators': 100, 'learning_rate': 0.1},\n",
       " {'learning_rate': 0.1, 'iterations': 100, 'depth': 10},\n",
       " {'learning_rate': 0.1, 'iterations': 100, 'depth': 10})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Define target variables\n",
    "y_mlm = train_data['MLM']\n",
    "y_hlm = train_data['HLM']\n",
    "\n",
    "# Reduced hyperparameters for demonstration\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10]\n",
    "}\n",
    "\n",
    "param_dist_gbr = {\n",
    "    'n_estimators': [100],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "param_dist_cat = {\n",
    "    'iterations': [100],\n",
    "    'learning_rate': [0.1],\n",
    "    'depth': [10]\n",
    "}\n",
    "\n",
    "# Error handling for hyperparameter tuning\n",
    "try:\n",
    "    rf_mlm_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_distributions=param_dist_rf, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rf_mlm_search.fit(X_poly, y_mlm)\n",
    "    best_rf_mlm_params = rf_mlm_search.best_params_\n",
    "except:\n",
    "    best_rf_mlm_params = {'n_estimators': 100, 'max_depth': 10}\n",
    "\n",
    "try:\n",
    "    rf_hlm_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_distributions=param_dist_rf, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    rf_hlm_search.fit(X_poly, y_hlm)\n",
    "    best_rf_hlm_params = rf_hlm_search.best_params_\n",
    "except:\n",
    "    best_rf_hlm_params = {'n_estimators': 100, 'max_depth': 10}\n",
    "\n",
    "try:\n",
    "    gbr_mlm_search = RandomizedSearchCV(GradientBoostingRegressor(random_state=42), param_distributions=param_dist_gbr, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    gbr_mlm_search.fit(X_poly, y_mlm)\n",
    "    best_gbr_mlm_params = gbr_mlm_search.best_params_\n",
    "except:\n",
    "    best_gbr_mlm_params = {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "\n",
    "try:\n",
    "    gbr_hlm_search = RandomizedSearchCV(GradientBoostingRegressor(random_state=42), param_distributions=param_dist_gbr, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    gbr_hlm_search.fit(X_poly, y_hlm)\n",
    "    best_gbr_hlm_params = gbr_hlm_search.best_params_\n",
    "except:\n",
    "    best_gbr_hlm_params = {'n_estimators': 100, 'learning_rate': 0.1}\n",
    "\n",
    "try:\n",
    "    cat_mlm_search = RandomizedSearchCV(CatBoostRegressor(random_state=42, verbose=0), param_distributions=param_dist_cat, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    cat_mlm_search.fit(X_poly, y_mlm)\n",
    "    best_cat_mlm_params = cat_mlm_search.best_params_\n",
    "except:\n",
    "    best_cat_mlm_params = {'iterations': 100, 'learning_rate': 0.1, 'depth': 10}\n",
    "\n",
    "try:\n",
    "    cat_hlm_search = RandomizedSearchCV(CatBoostRegressor(random_state=42, verbose=0), param_distributions=param_dist_cat, n_iter=1, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    cat_hlm_search.fit(X_poly, y_hlm)\n",
    "    best_cat_hlm_params = cat_hlm_search.best_params_\n",
    "except:\n",
    "    best_cat_hlm_params = {'iterations': 100, 'learning_rate': 0.1, 'depth': 10}\n",
    "\n",
    "best_rf_mlm_params, best_rf_hlm_params, best_gbr_mlm_params, best_gbr_hlm_params, best_cat_mlm_params, best_cat_hlm_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e280a9",
   "metadata": {},
   "source": [
    "## 4. Model Training with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4c368d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x26d5e2b3a50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# Train Random Forest with best hyperparameters\n",
    "rf_mlm_best = RandomForestRegressor(**best_rf_mlm_params, random_state=42)\n",
    "rf_mlm_best.fit(X_poly, y_mlm)\n",
    "\n",
    "rf_hlm_best = RandomForestRegressor(**best_rf_hlm_params, random_state=42)\n",
    "rf_hlm_best.fit(X_poly, y_hlm)\n",
    "\n",
    "# Train Gradient Boosting Regressor with best hyperparameters\n",
    "gbr_mlm_best = GradientBoostingRegressor(**best_gbr_mlm_params, random_state=42)\n",
    "gbr_mlm_best.fit(X_poly, y_mlm)\n",
    "\n",
    "gbr_hlm_best = GradientBoostingRegressor(**best_gbr_hlm_params, random_state=42)\n",
    "gbr_hlm_best.fit(X_poly, y_hlm)\n",
    "\n",
    "# Train CatBoost with best hyperparameters\n",
    "cat_mlm_best = CatBoostRegressor(**best_cat_mlm_params, random_state=42, verbose=0)\n",
    "cat_mlm_best.fit(X_poly, y_mlm)\n",
    "\n",
    "cat_hlm_best = CatBoostRegressor(**best_cat_hlm_params, random_state=42, verbose=0)\n",
    "cat_hlm_best.fit(X_poly, y_hlm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7255f1f",
   "metadata": {},
   "source": [
    "## 5. Predictions and Submission Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252413eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predictions\n",
    "rf_mlm_preds = rf_mlm_best.predict(X_test_poly)\n",
    "rf_hlm_preds = rf_hlm_best.predict(X_test_poly)\n",
    "\n",
    "gbr_mlm_preds = gbr_mlm_best.predict(X_test_poly)\n",
    "gbr_hlm_preds = gbr_hlm_best.predict(X_test_poly)\n",
    "\n",
    "cat_mlm_preds = cat_mlm_best.predict(X_test_poly)\n",
    "cat_hlm_preds = cat_hlm_best.predict(X_test_poly)\n",
    "\n",
    "# Averaging predictions from the three models\n",
    "final_pred_mlm = (rf_mlm_preds + gbr_mlm_preds + cat_mlm_preds) / 3\n",
    "final_pred_hlm = (rf_hlm_preds + gbr_hlm_preds + cat_hlm_preds) / 3\n",
    "\n",
    "# Create final submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'MLM': final_pred_mlm,\n",
    "    'HLM': final_pred_hlm\n",
    "})\n",
    "\n",
    "# Save submission to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
